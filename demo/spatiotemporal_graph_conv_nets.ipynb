{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/ziyujia/GraphSleepNet\n"
      ],
      "metadata": {
        "id": "tohB_NssD75W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generic\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Misc\n",
        "from scipy.sparse.linalg import eigs\n",
        "from scipy.spatial import distance_matrix\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Tensorflow\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "from keras import models\n",
        "from keras.layers import Layer\n",
        "from keras.layers.core import Lambda\n",
        "from tensorflow.keras.layers import LayerNormalization\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "SuDHw6q1YijB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "119d9c9d-abcb-49ef-daa3-5113db246eb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo0t60h4Hh4s",
        "outputId": "9172b5cb-a3d5-443c-ce73-d2140aa96e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ],
      "metadata": {
        "id": "2SL851ldtEKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "cov_idx_dict = {'lab': (1,6),\n",
        "               'session': (6,10),\n",
        "               'x': (10,11),\n",
        "               'y': (11,12),\n",
        "               'z': (12,13),\n",
        "               'waveform amplitude': (13,14),\n",
        "               'waveform width': (14,15),\n",
        "               'paw speed': (15,16),\n",
        "               'nose speed': (16,17),\n",
        "               'pupil diameter': (17,18),\n",
        "               'motion energy': (18,19),\n",
        "               'stimuli': (19,21),\n",
        "               'go cue': (21,22),\n",
        "               'choice': (22,24),\n",
        "               'reward': (24,26),\n",
        "               'wheel velocity': (26,27),\n",
        "               'mouse prior': (27,28),\n",
        "               'lick': (28,29),\n",
        "               'decision strategy (GLM-HMM)': (29,33),\n",
        "               'brain region': (33,38),\n",
        "               'noise': (38,39),\n",
        "               'all': (1,39)}\n",
        "''';"
      ],
      "metadata": {
        "id": "DPJ-5kS41j9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"drive/MyDrive/Neural/ibl/\"\n",
        "\n",
        "firing_rates = np.load(\"\".join([path, \"unsorted/unsorted_firing_rates.npy\"]))\n",
        "firing_rates = firing_rates.transpose([1,0,2])\n",
        "n_channels, n_trials, n_time_bins = firing_rates.shape\n",
        "\n",
        "#aggregate_amps = np.load(\"\".join([path, \"unsorted_aggregate_amps.npy\"]))\n",
        "#aggregate_amps = aggregate_amps.transpose([1,0,2])\n",
        "\n",
        "neural_feature = np.load(\"\".join([path, \"sorted/d23a44ef-1402-4ed7-97f5-47e9a7a504d9_feature.npy\"]))\n",
        "decisions = neural_feature[:,:,:,22:24].sum(2)[0,:,:]\n",
        "\n",
        "probe_geometry = np.load(\"\".join([path, \"np1_channel_map.npy\"]))\n",
        "\n",
        "unsorted_fire_rates = firing_rates.transpose([1,2,0]).reshape(-1, n_time_bins*n_channels)\n",
        "for k in range(n_time_bins):\n",
        "  unsorted_fire_rates[:, k*n_channels:(k+1)*n_channels] = (unsorted_fire_rates[:, k*n_channels:(k+1)*n_channels] - unsorted_fire_rates[:, k*n_channels:(k+1)*n_channels].mean()) / unsorted_fire_rates[:, k*n_channels:(k+1)*n_channels].std()\n",
        "\n",
        "#resorted_aggregate_amps = aggregate_amps.transpose([1,2,0]).reshape(-1, n_time_bins*n_channels)\n",
        "#for k in range(n_time_bins):\n",
        "#  resorted_aggregate_amps[:, k*n_channels:(k+1)*n_channels] = (resorted_aggregate_amps[:, k*n_channels:(k+1)*n_channels] - resorted_aggregate_amps[:, k*n_channels:(k+1)*n_channels].mean()) / resorted_aggregate_amps[:, k*n_channels:(k+1)*n_channels].std()\n",
        "\n",
        "\n",
        "#Xs = np.concatenate(\n",
        "#      [resorted_fire_rates.reshape(-1, n_time_bins, n_channels)[:,:,:,np.newaxis],\n",
        "#       resorted_aggregate_amps.reshape(-1, n_time_bins, n_channels)[:,:,:,np.newaxis]], 3\n",
        "#)\n",
        "Xs = unsorted_fire_rates.reshape(-1, n_time_bins, n_channels)[:,:,:,np.newaxis]\n",
        "ys = decisions\n",
        "print(\"Number of channels is\", n_channels)\n",
        "print(\"Number of trials is\", n_trials)\n",
        "print(\"Number of time bins is\", n_time_bins)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEjeWK04l5nB",
        "outputId": "ffe849f3-b715-4164-89fb-7591d0929dd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of channels is 384\n",
            "Number of trials is 286\n",
            "Number of time bins is 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find brain ROIs of each channel:"
      ],
      "metadata": {
        "id": "U-sF8RvOd-iM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load brain regions by channel and depth data\n",
        "#ROI_by_channel_depth = np.load('drive/MyDrive/ibl/ROI_by_channel_depth.npy')\n",
        "#channels = ROI_by_channel_depth[:,0].astype(int)\n",
        "#depths = ROI_by_channel_depth[:,1].astype(float)\n",
        "#ROIs = ROI_by_channel_depth[:,2]"
      ],
      "metadata": {
        "id": "CLAmZEwMd-uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Match channels to brain regions by channel index and depth\n",
        "#brain_regions = []\n",
        "#for i in np.arange(n_channels):\n",
        "#  region = ROIs[np.where(channels == i)]\n",
        "#  if len(region) == 0:\n",
        "#    region = (ROIs[np.where(depths == probe_geometry[i,1])])\n",
        "#  if len(region) == 0:\n",
        "#    region = ['NA']\n",
        "#  region = region[0]\n",
        "#  if (region == 'ml') or (region == 'cing') or (region == 'or'):\n",
        "#    region = 'NA'\n",
        "#  brain_regions.append(region)"
      ],
      "metadata": {
        "id": "wblLeZgmeWxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical data to integer-valued array\n",
        "#brain_region_dict = {'NA':0, 'CA1':1, 'DG':2, 'Eth':3, 'LP':4, 'PO':5, 'PPC':6, 'TH':7, 'VPLpc':8, 'alv':9, 'fp':10}\n",
        "#brain_regions = [brain_region_dict[i] for i in brain_regions]"
      ],
      "metadata": {
        "id": "4cXmn1lNla9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ST-GCN"
      ],
      "metadata": {
        "id": "riv1fUFyV9bw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_rescaled_graph_Laplacian(A):\n",
        "    '''\n",
        "    Compute \\tilde{L} = (2 / \\lambda_max) * L - I_M, \n",
        "            L = D - A, D is degree matrix of A, \n",
        "            \\lambda_max is the largest eigenvalue of L\n",
        "    Input:\n",
        "    ----------\n",
        "    A: (M, M) adjacency matrix, M is the num of vertices (neurons / channels)\n",
        "\n",
        "    Output:\n",
        "    ----------\n",
        "    L_tilde: (M, M) rescaled graph Laplacian\n",
        "    '''\n",
        "    assert A.shape[0] == A.shape[1]\n",
        "    M = A.shape[0]   \n",
        "    # Compute the degree matrix of A\n",
        "    D = np.diag(np.sum(A, axis=1))\n",
        "    # Compute the graph Laplacian\n",
        "    L = D - A   \n",
        "    # Find the largest real eigenvalues \n",
        "    lambda_max = (np.linalg.eig(L)[0])[0]   \n",
        "    # Compute the rescaled graph Laplacian\n",
        "    L_tilde = (2 / lambda_max) * L - np.identity(M)\n",
        "    \n",
        "    return L_tilde\n",
        "\n",
        "\n",
        "def calc_cheb_polynomial(L_tilde, K):\n",
        "    '''\n",
        "    Recursively compute K chebyshev polynomials from T_0 to T_{K-1}, T_0 = 1, T_1 = x\n",
        "    Input:\n",
        "    ----------\n",
        "    L_tilde: (M, M) rescaled graph Laplacian\n",
        "    K: Order of chebyshev polynomials\n",
        "\n",
        "    Output:\n",
        "    ----------\n",
        "    cheb_poly: A list of K chebyshev polynomials\n",
        "    '''\n",
        "    M = L_tilde.shape[0]\n",
        "\n",
        "    # Recursively compute chebyshev polynomials\n",
        "    cheb_poly = [np.identity(M), L_tilde.copy()]\n",
        "    for i in range(2, K):\n",
        "        cheb_poly.append(2 * L_tilde * cheb_poly[i - 1] - cheb_poly[i - 2]) \n",
        "    \n",
        "    return cheb_poly"
      ],
      "metadata": {
        "id": "ClKYA0u9_vS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Temporal_Attention_Layer(Layer):\n",
        "    '''\n",
        "    Compute temporal attention scores.\n",
        "    --------\n",
        "    Input:  (n_trials, n_time_bins, n_nodes, n_features)\n",
        "    Output: (n_trials, n_time_bins, n_time_bins)\n",
        "    '''\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Temporal_Attention_Layer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        _, n_time_bins, n_nodes, n_features = input_shape\n",
        "\n",
        "        self.U1 = self.add_weight(name='U1', shape=(n_nodes, 1), initializer='uniform', trainable=True)\n",
        "        self.U2 = self.add_weight(name='U2', shape=(n_features, n_nodes), initializer='uniform', trainable=True)\n",
        "        self.U3 = self.add_weight(name='U3', shape=(n_features, ), initializer='uniform', trainable=True)\n",
        "        self.be = self.add_weight(name='be', shape=(1, n_time_bins, n_time_bins), initializer='uniform', trainable=True)\n",
        "        self.Ve = self.add_weight(name='Ve', shape=(n_time_bins, n_time_bins), initializer='uniform', trainable=True)\n",
        "        super(Temporal_Attention_Layer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        _, n_time_bins, n_nodes, n_features = x.shape\n",
        "        \n",
        "        # (n_trials, n_time_bins, n_nodes)\n",
        "        lhs = K.dot(tf.transpose(x, perm=[0,1,3,2]), self.U1)\n",
        "        lhs = tf.reshape(lhs, [tf.shape(x)[0], n_time_bins, n_features])\n",
        "        lhs = K.dot(lhs, self.U2)\n",
        "        \n",
        "        # (n_trials, n_nodes, n_time_bins)\n",
        "        rhs = K.dot(self.U3, tf.transpose(x, perm=[2,0,3,1])) \n",
        "        rhs = tf.transpose(rhs, perm=[1,0,2])\n",
        "        \n",
        "        # (n_trials, n_time_bins, n_time_bins)\n",
        "        product = K.batch_dot(lhs, rhs)\n",
        "        \n",
        "        S = tf.transpose(K.dot(self.Ve, tf.transpose(K.sigmoid(product + self.be), perm=[1, 2, 0])), perm=[2, 0, 1])\n",
        "        \n",
        "        # Normalization\n",
        "        S = S - K.max(S, axis = 1, keepdims = True)\n",
        "        exp = K.exp(S)\n",
        "        S_normalized = exp / K.sum(exp, axis = 1, keepdims = True)\n",
        "        return S_normalized"
      ],
      "metadata": {
        "id": "5syXKrsz_Y3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reshape_dot(x):\n",
        "  '''\n",
        "  Apply temporal attention to x.\n",
        "  Input:  [x, temporal_attention_scores]\n",
        "  '''\n",
        "  x, temporal_attention_scores = x\n",
        "  return tf.reshape(\n",
        "      K.batch_dot(\n",
        "          tf.reshape(tf.transpose(x, perm = [0,2,3,1]), (tf.shape(x)[0], -1, tf.shape(x)[1])), \n",
        "          temporal_attention_scores),\n",
        "      [-1, x.shape[1],x.shape[2],x.shape[3]])"
      ],
      "metadata": {
        "id": "b5mtC1QrFHBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Spatial_Attention_Layer(Layer):\n",
        "    '''\n",
        "    Compute spatial attention scores.\n",
        "    --------\n",
        "    Input:  (n_trials, n_time_bins, n_nodes, n_features)\n",
        "    Output: (n_trials, n_nodes, n_nodes)\n",
        "    '''\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Spatial_Attention_Layer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        _, n_time_bins, n_nodes, n_features = input_shape\n",
        "        self.W1 = self.add_weight(name='W1', shape=(n_time_bins, 1), initializer='uniform', trainable=True)\n",
        "        self.W2 = self.add_weight(name='W2', shape=(n_features, n_time_bins), initializer='uniform', trainable=True)\n",
        "        self.W3 = self.add_weight(name='W3', shape=(n_features, ), initializer='uniform', trainable=True)\n",
        "        self.bs = self.add_weight(name='bs', shape=(1, n_nodes, n_nodes), initializer='uniform', trainable=True)\n",
        "        self.Vs = self.add_weight(name='Vs', shape=(n_nodes, n_nodes), initializer='uniform', trainable=True)\n",
        "        super(Spatial_Attention_Layer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        _, n_time_bins, n_nodes, n_features = x.shape\n",
        "        \n",
        "        # (n_trials, n_nodes, n_time_bins)\n",
        "        lhs = K.dot(tf.transpose(x, perm = [0,2,3,1]), self.W1)\n",
        "        lhs = tf.reshape(lhs, [tf.shape(x)[0], n_nodes, n_features])\n",
        "        lhs = K.dot(lhs, self.W2)\n",
        "        \n",
        "        # (n_trials, n_time_bins, n_nodes)\n",
        "        rhs = K.dot(self.W3, tf.transpose(x, perm = [1,0,3,2])) \n",
        "        rhs = tf.transpose(rhs, perm = [1,0,2])\n",
        "        \n",
        "        # (n_trials, n_nodes, n_nodes)\n",
        "        product = K.batch_dot(lhs, rhs)\n",
        "        \n",
        "        S = tf.transpose(K.dot(self.Vs, tf.transpose(K.sigmoid(product + self.bs), perm = [1, 2, 0])), perm = [2, 0, 1])\n",
        "        \n",
        "        # Normalization\n",
        "        S = S - K.max(S, axis = 1, keepdims = True)\n",
        "        exp = K.exp(S)\n",
        "        S_normalized = exp / K.sum(exp, axis = 1, keepdims = True)\n",
        "        return S_normalized"
      ],
      "metadata": {
        "id": "DLKaJOgg_pwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Spatial_Conv_with_Spatial_Attention(Layer):\n",
        "    '''\n",
        "    K-order spatial graph convolution.\n",
        "    --------\n",
        "    Input:  - x   (n_trials, n_time_bins, n_nodes, n_features)\n",
        "            - spatial_attention_scores (n_trials, n_nodes, n_nodes)\n",
        "    Output: (n_trials, n_time_bins, n_nodes, n_filters)\n",
        "    '''\n",
        "    def __init__(self, n_filters, k, cheb_poly, **kwargs):\n",
        "        self.k = k\n",
        "        self.n_filters = n_filters\n",
        "        self.cheb_poly = cheb_poly\n",
        "        super(Spatial_Conv_with_Spatial_Attention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        x_shape, spatial_attention_scores_shape = input_shape\n",
        "        _, n_time_bins, n_nodes, n_features = x_shape\n",
        "        self.Theta = self.add_weight(name='Theta', shape=(self.k, n_features, self.n_filters), initializer='uniform', trainable=True)\n",
        "        super(Spatial_Conv_with_Spatial_Attention, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        assert isinstance(x, list)\n",
        "        assert len(x)==2 \n",
        "        x, spatial_attention_scores = x\n",
        "        _, n_time_bins, n_nodes, n_features = x.shape\n",
        "        \n",
        "        outputs=[]\n",
        "        for time_bin in range(n_time_bins):\n",
        "            # (n_trials, n_nodes, n_features)\n",
        "            graph_signal = x[:, time_bin, :, :]\n",
        "            # (n_trials, n_nodes, n_filters)\n",
        "            output = tf.zeros(shape = (tf.shape(x)[0], n_nodes, self.n_filters))\n",
        "            \n",
        "            for k in range(self.k):\n",
        "                # (n_nodes, n_nodes)\n",
        "                T_k = self.cheb_poly[k]\n",
        "                    \n",
        "                # (n_trials, n_nodes, n_nodes)\n",
        "                T_k_with_AT = T_k * spatial_attention_scores\n",
        "\n",
        "                # (n_features, n_filters)\n",
        "                theta_k = self.Theta[k]\n",
        "\n",
        "                # shape is (n_trials, n_nodes, n_features)\n",
        "                rhs = K.batch_dot(tf.transpose(T_k_with_AT, perm = [0, 2, 1]), graph_signal)\n",
        "\n",
        "                output = output + K.dot(rhs, theta_k)\n",
        "            outputs.append(tf.expand_dims(output,1))\n",
        "            \n",
        "        return K.relu(K.concatenate(outputs, axis = 1))"
      ],
      "metadata": {
        "id": "z_7nFXDJAfJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Spatial_Temporal_Convolution_Block(x, k, n_spatial_filters, n_time_filters, cheb_poly, time_conv_strides, time_conv_kernel, i):\n",
        "    '''\n",
        "    Spatial-Temporal Convolution Block.\n",
        "    -------\n",
        "    x: (n_trials, n_time_bins, n_nodes, n_features)\n",
        "    '''     \n",
        "    # Apply Temporal Attention (n_trials, n_time_bins, n_time_bins)\n",
        "    temporal_attention_scores = Temporal_Attention_Layer()(x)\n",
        "    x_temporal_attention = Lambda(reshape_dot, name = 'reshape_dot' + str(i))([x, temporal_attention_scores])\n",
        "\n",
        "    # Apply Spatial Attention (n_trials, n_nodes, n_nodes)\n",
        "    spatial_attention = Spatial_Attention_Layer()(x_temporal_attention)\n",
        "    \n",
        "    # Apply Spatial Graph Convolution with Chebyshev polynomial expansions (n_trials, n_time_bins, n_nodes, n_spatial_filters)\n",
        "    spatial_conv_output = Spatial_Conv_with_Spatial_Attention(n_spatial_filters, k, cheb_poly)([x, spatial_attention])\n",
        "    \n",
        "    # Apply Temporal Convolution (n_trials, n_time_bins, n_nodes, n_time_filters)\n",
        "    time_conv_output = layers.Conv2D(\n",
        "        filters = n_time_filters, \n",
        "        kernel_size = (time_conv_kernel, 1), \n",
        "        padding = 'same', \n",
        "        strides = (time_conv_strides, 1)\n",
        "    )(spatial_conv_output)\n",
        "\n",
        "    # Apply Residual Shortcut (n_trials, n_time_bins, n_nodes, n_time_filters)\n",
        "    x_residual = layers.Conv2D(\n",
        "        filters = n_time_filters, \n",
        "        kernel_size = (1, 1), \n",
        "        strides = (1, time_conv_strides)\n",
        "    )(x)\n",
        "    \n",
        "    # Layer Normalization\n",
        "    layer_norm = LayerNormalization(name = None, axis = 3, epsilon = 1e-8, dtype = tf.float32)\n",
        "    relu_x = K.relu(x_residual + time_conv_output)\n",
        "    output = layer_norm(relu_x)\n",
        "    return output"
      ],
      "metadata": {
        "id": "ZBKjflcKAmi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_STGCN(k, data_shape, n_spatial_filters, n_time_filters, cheb_poly, time_conv_strides, time_conv_kernel, \n",
        "                n_blocks, hidden_sizes, opt, regularizer, drop_out):\n",
        "    \n",
        "    # Input:  (*, n_time_bins, n_nodes, n_features)\n",
        "    data_layer = layers.Input(shape = data_shape, name = 'Input Data')\n",
        "    \n",
        "    # Spatial Temporal Convolution Block\n",
        "    output = Spatial_Temporal_Convolution_Block(data_layer, k, n_spatial_filters, n_time_filters, cheb_poly, time_conv_strides, time_conv_kernel, 0)\n",
        "    for i in range(1, n_blocks):\n",
        "        output = Spatial_Temporal_Convolution_Block(output, k, n_spatial_filters, n_time_filters, cheb_poly, time_conv_strides, time_conv_kernel, i)\n",
        "   \n",
        "    # Global Dense Layers\n",
        "    output = layers.Flatten()(output)\n",
        "    for size in hidden_sizes:\n",
        "        output = layers.Dense(size)(output)\n",
        "    \n",
        "    # Drop Out\n",
        "    if drop_out!=0:\n",
        "        output = layers.Dropout(drop_out)(output)\n",
        "    \n",
        "    # Classifier\n",
        "    output = layers.Dense(2, activation = 'softmax', kernel_regularizer = regularizer)(output)\n",
        "    \n",
        "    model = models.Model(inputs = data_layer, outputs = output)\n",
        "    \n",
        "    METRICS = [keras.metrics.Accuracy(name=\"accuracy\"), keras.metrics.AUC(name='auc')]\n",
        "\n",
        "    model.compile(\n",
        "        optimizer = opt,\n",
        "        loss = 'categorical_crossentropy',\n",
        "        metrics = METRICS,\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "d18eSk9YAq6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "p0yb2zFI5thu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs   = 50\n",
        "batch_size = 15\n",
        "optimizer  = \"SGD\"\n",
        "learn_rate = 1e-3\n",
        "lr_decay   = 2e-6\n",
        "\n",
        "n_features            = 1\n",
        "data_shape            = (n_time_bins, n_channels, n_features)\n",
        "K_order               = 3\n",
        "n_blocks              = 1\n",
        "n_spatial_filters     = 10 \n",
        "n_time_filters        = 10 \n",
        "time_conv_strides     = 1\n",
        "time_conv_kernel      = 3 \n",
        "hidden_sizes          = np.array([64, 32], dtype=int)\n",
        "drop_out              = 0 \n",
        "l1_penalty            = 0.01  \n",
        "l2_penalty            = 0.01  \n",
        "\n",
        "if optimizer == \"adam\":\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate = learn_rate, decay = lr_decay, clipvalue = .5) \n",
        "elif optimizer == \"SGD\":\n",
        "    opt = tf.keras.optimizers.SGD(learning_rate = learn_rate, decay = lr_decay, clipvalue = .5) \n",
        "\n",
        "if l1_penalty != 0 and l2_penalty != 0:\n",
        "    regularizer = keras.regularizers.l1_l2(l1 = l1_penalty, l2 = l2_penalty)\n",
        "elif l1_penalty != 0 and l2_penalty == 0:\n",
        "    regularizer = keras.regularizers.l1(l1_penalty)\n",
        "elif l1_penalty == 0 and l2_penalty != 0:\n",
        "    regularizer = keras.regularizers.l2(l2_penalty)\n",
        "else:\n",
        "    regularizer = None"
      ],
      "metadata": {
        "id": "DDjIUYzWBKEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the adjacency matrix\n",
        "A = np.ones((n_channels, n_channels))\n",
        "#A = np.zeros((n_channels, n_channels))\n",
        "#for i in range(n_channels):\n",
        "#  for j in range(n_channels):\n",
        "#    if brain_regions[i] == brain_regions[j]:\n",
        "#      A[i, j] = 1"
      ],
      "metadata": {
        "id": "5VZ5V8jlgF77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Chebyshev polynomials\n",
        "L = calc_rescaled_graph_Laplacian(A)\n",
        "cheb_poly = calc_cheb_polynomial(L, K_order)"
      ],
      "metadata": {
        "id": "Pc0jud-080yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Fold CV"
      ],
      "metadata": {
        "id": "a4Q1ObY7Gygy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits = 10, shuffle = True, random_state = seed) \n",
        "\n",
        "fold = 0\n",
        "cv_accs = []\n",
        "cv_aucs = []\n",
        "for train, test in kfold.split(Xs, ys):\n",
        "\n",
        "  model = build_STGCN(\n",
        "    K_order, data_shape, n_spatial_filters, n_time_filters, cheb_poly, time_conv_strides, time_conv_kernel, \n",
        "    n_blocks, hidden_sizes, opt, regularizer, drop_out)\n",
        "  \n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold} ...')\n",
        "\n",
        "  model.fit(Xs[train], ys[train],\n",
        "        epochs = n_epochs,\n",
        "        batch_size = batch_size,\n",
        "        shuffle = True,\n",
        "        verbose = 1)\n",
        "  \n",
        "  test_probs = model.predict(Xs[test])\n",
        "  test_preds = test_probs.argmax(1)\n",
        "  acc = accuracy_score(ys[test].argmax(1), test_preds)\n",
        "  auc = roc_auc_score(ys[test], test_probs)\n",
        "  cv_accs.append(acc)\n",
        "  cv_aucs.append(auc)\n",
        "  print(f'Test accuracy: {acc}, AUC: {auc} .')\n",
        "  fold += 1\n",
        "\n",
        "print(f'Average {fold}-fold CV accuracy: {np.mean(cv_accs)}, AUC: {np.mean(cv_aucs)} .')\n",
        "print(f'SD of {fold}-fold CV accuracy: {np.std(cv_accs)}, AUC: {np.std(cv_aucs)} .')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmkECNH3I--L",
        "outputId": "f6c1f5a2-6250-4dee-8100-66b3a9a025f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py:436: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  nparray = values.astype(dtype.as_numpy_dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 0 ...\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 25s 52ms/step - loss: 41.7058 - accuracy: 0.4319 - auc: 0.6042\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 20.9430 - accuracy: 0.4942 - auc: 0.7038\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 17.6254 - accuracy: 0.4455 - auc: 0.6307\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 6.1386 - accuracy: 0.3463 - auc: 0.8212\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 4.4223 - accuracy: 0.3794 - auc: 0.8700\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 5.5227 - accuracy: 0.3696 - auc: 0.7610\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.8437 - accuracy: 0.2821 - auc: 0.9608\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 3.3695 - accuracy: 0.2938 - auc: 0.8761\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1607 - accuracy: 0.3521 - auc: 1.0000\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1604 - accuracy: 0.3560 - auc: 1.0000\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1604 - accuracy: 0.3482 - auc: 1.0000\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1601 - accuracy: 0.3619 - auc: 1.0000\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1598 - accuracy: 0.3541 - auc: 1.0000\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1595 - accuracy: 0.3716 - auc: 1.0000\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1593 - accuracy: 0.3463 - auc: 1.0000\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1591 - accuracy: 0.3677 - auc: 1.0000\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1588 - accuracy: 0.3580 - auc: 1.0000\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1586 - accuracy: 0.3541 - auc: 1.0000\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1583 - accuracy: 0.3638 - auc: 1.0000\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1581 - accuracy: 0.3599 - auc: 1.0000\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1578 - accuracy: 0.3580 - auc: 1.0000\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1576 - accuracy: 0.3502 - auc: 1.0000\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1574 - accuracy: 0.3541 - auc: 1.0000\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1572 - accuracy: 0.3541 - auc: 1.0000\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1570 - accuracy: 0.3658 - auc: 1.0000\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1567 - accuracy: 0.3580 - auc: 1.0000\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1565 - accuracy: 0.3599 - auc: 1.0000\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1563 - accuracy: 0.3560 - auc: 1.0000\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1560 - accuracy: 0.3580 - auc: 1.0000\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1558 - accuracy: 0.3599 - auc: 1.0000\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1556 - accuracy: 0.3482 - auc: 1.0000\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1554 - accuracy: 0.3541 - auc: 1.0000\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1554 - accuracy: 0.3521 - auc: 1.0000\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1549 - accuracy: 0.3541 - auc: 1.0000\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1547 - accuracy: 0.3560 - auc: 1.0000\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1545 - accuracy: 0.3521 - auc: 1.0000\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1545 - accuracy: 0.3482 - auc: 1.0000\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1540 - accuracy: 0.3560 - auc: 1.0000\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1538 - accuracy: 0.3560 - auc: 1.0000\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1536 - accuracy: 0.3521 - auc: 1.0000\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1533 - accuracy: 0.3502 - auc: 1.0000\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1531 - accuracy: 0.3424 - auc: 1.0000\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1529 - accuracy: 0.3444 - auc: 1.0000\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1527 - accuracy: 0.3541 - auc: 1.0000\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1525 - accuracy: 0.3463 - auc: 1.0000\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1522 - accuracy: 0.3444 - auc: 1.0000\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1520 - accuracy: 0.3502 - auc: 1.0000\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1518 - accuracy: 0.3463 - auc: 1.0000\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1516 - accuracy: 0.3405 - auc: 1.0000\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1514 - accuracy: 0.3405 - auc: 1.0000\n",
            "Test accuracy: 0.896551724137931, AUC: 0.9545454545454546 .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py:436: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  nparray = values.astype(dtype.as_numpy_dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 8s 53ms/step - loss: 26.9840 - accuracy: 0.4572 - auc: 0.6089\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 13.7564 - accuracy: 0.2918 - auc: 0.6991\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 4.5008 - accuracy: 0.1946 - auc: 0.8501\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.3850 - accuracy: 0.0817 - auc: 0.9846\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 1.4942 - accuracy: 0.0467 - auc: 0.9137\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 3.7878 - accuracy: 0.2957 - auc: 0.7973\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1714 - accuracy: 0.0331 - auc: 1.0000\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1684 - accuracy: 0.0331 - auc: 1.0000\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1678 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1671 - accuracy: 0.0350 - auc: 1.0000\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1668 - accuracy: 0.0311 - auc: 1.0000\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1665 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1662 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1661 - accuracy: 0.0409 - auc: 1.0000\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1655 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1652 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1650 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1647 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1644 - accuracy: 0.0350 - auc: 1.0000\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1642 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1639 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1638 - accuracy: 0.0253 - auc: 1.0000\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1634 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1632 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1629 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1627 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1625 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1622 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1620 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1617 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1615 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1613 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1610 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1608 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1606 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1603 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1601 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1599 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1597 - accuracy: 0.0350 - auc: 1.0000\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1594 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1592 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1590 - accuracy: 0.0350 - auc: 1.0000\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1587 - accuracy: 0.0350 - auc: 1.0000\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1585 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1583 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1581 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 1s 59ms/step - loss: 0.1578 - accuracy: 0.0370 - auc: 1.0000\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1576 - accuracy: 0.0350 - auc: 1.0000\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1574 - accuracy: 0.0331 - auc: 1.0000\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1572 - accuracy: 0.0350 - auc: 1.0000\n",
            "Test accuracy: 0.8275862068965517, AUC: 0.9155844155844155 .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py:436: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  nparray = values.astype(dtype.as_numpy_dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 9s 52ms/step - loss: 22.4625 - accuracy: 0.3638 - auc: 0.6127\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 16.3854 - accuracy: 0.3599 - auc: 0.6472\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 9.4955 - accuracy: 0.3502 - auc: 0.7383\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 6.7815 - accuracy: 0.2802 - auc: 0.7677\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 7.4059 - accuracy: 0.2140 - auc: 0.7682\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 6.1181 - accuracy: 0.2724 - auc: 0.7320\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 1.4408 - accuracy: 0.1965 - auc: 0.9376\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 4.7817 - accuracy: 0.2490 - auc: 0.7569\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 1.8142 - accuracy: 0.2335 - auc: 0.9204\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.6493 - accuracy: 0.2451 - auc: 0.9700\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 2.7852 - accuracy: 0.2043 - auc: 0.8472\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.2253 - accuracy: 0.2490 - auc: 0.9951\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 2.7571 - accuracy: 0.2218 - auc: 0.8657\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 2.3868 - accuracy: 0.2607 - auc: 0.8681\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 1.4820 - accuracy: 0.3191 - auc: 0.9296\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1517 - accuracy: 0.2743 - auc: 1.0000\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1495 - accuracy: 0.2802 - auc: 1.0000\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1491 - accuracy: 0.2763 - auc: 1.0000\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.8574 - accuracy: 0.2510 - auc: 0.9546\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1488 - accuracy: 0.2821 - auc: 1.0000\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1483 - accuracy: 0.3054 - auc: 1.0000\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1480 - accuracy: 0.2471 - auc: 1.0000\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1489 - accuracy: 0.3191 - auc: 1.0000\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1478 - accuracy: 0.2724 - auc: 1.0000\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1473 - accuracy: 0.2821 - auc: 1.0000\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1471 - accuracy: 0.2840 - auc: 1.0000\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1469 - accuracy: 0.2704 - auc: 1.0000\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1468 - accuracy: 0.2840 - auc: 1.0000\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1466 - accuracy: 0.2957 - auc: 1.0000\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1462 - accuracy: 0.2899 - auc: 1.0000\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1460 - accuracy: 0.2685 - auc: 1.0000\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1459 - accuracy: 0.2626 - auc: 1.0000\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1457 - accuracy: 0.2802 - auc: 1.0000\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1453 - accuracy: 0.2938 - auc: 1.0000\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1451 - accuracy: 0.2588 - auc: 1.0000\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1449 - accuracy: 0.2957 - auc: 1.0000\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1448 - accuracy: 0.2626 - auc: 1.0000\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1445 - accuracy: 0.2821 - auc: 1.0000\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1442 - accuracy: 0.2646 - auc: 1.0000\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1440 - accuracy: 0.2724 - auc: 1.0000\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1438 - accuracy: 0.2724 - auc: 1.0000\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1436 - accuracy: 0.2549 - auc: 1.0000\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1434 - accuracy: 0.2840 - auc: 1.0000\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1431 - accuracy: 0.2743 - auc: 1.0000\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1429 - accuracy: 0.2802 - auc: 1.0000\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1427 - accuracy: 0.2412 - auc: 1.0000\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1425 - accuracy: 0.2704 - auc: 1.0000\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1423 - accuracy: 0.2704 - auc: 1.0000\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1421 - accuracy: 0.2626 - auc: 1.0000\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1418 - accuracy: 0.2743 - auc: 1.0000\n",
            "Test accuracy: 0.8275862068965517, AUC: 0.95 .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py:436: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  nparray = values.astype(dtype.as_numpy_dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 9s 52ms/step - loss: 31.5035 - accuracy: 0.4981 - auc: 0.6317\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 28.5131 - accuracy: 0.3930 - auc: 0.5551\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 10.9320 - accuracy: 0.3230 - auc: 0.7639\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 11.8607 - accuracy: 0.3619 - auc: 0.6801\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 6.7791 - accuracy: 0.3502 - auc: 0.7754\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 6.5724 - accuracy: 0.3035 - auc: 0.7693\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 1.3335 - accuracy: 0.3327 - auc: 0.9328\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1626 - accuracy: 0.3716 - auc: 1.0000\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1767 - accuracy: 0.3619 - auc: 0.9998\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1572 - accuracy: 0.3658 - auc: 1.0000\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1570 - accuracy: 0.3794 - auc: 1.0000\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1568 - accuracy: 0.3813 - auc: 1.0000\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1565 - accuracy: 0.3833 - auc: 1.0000\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1563 - accuracy: 0.3658 - auc: 1.0000\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1560 - accuracy: 0.3735 - auc: 1.0000\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1558 - accuracy: 0.3658 - auc: 1.0000\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1556 - accuracy: 0.3735 - auc: 1.0000\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1554 - accuracy: 0.3716 - auc: 1.0000\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1552 - accuracy: 0.3735 - auc: 1.0000\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1549 - accuracy: 0.3638 - auc: 1.0000\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1547 - accuracy: 0.3833 - auc: 1.0000\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1544 - accuracy: 0.3658 - auc: 1.0000\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1543 - accuracy: 0.3716 - auc: 1.0000\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1540 - accuracy: 0.3658 - auc: 1.0000\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1538 - accuracy: 0.3794 - auc: 1.0000\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1536 - accuracy: 0.3658 - auc: 1.0000\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1533 - accuracy: 0.3774 - auc: 1.0000\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1531 - accuracy: 0.3580 - auc: 1.0000\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1529 - accuracy: 0.3774 - auc: 1.0000\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1526 - accuracy: 0.3716 - auc: 1.0000\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1524 - accuracy: 0.3774 - auc: 1.0000\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1522 - accuracy: 0.3735 - auc: 1.0000\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1520 - accuracy: 0.3638 - auc: 1.0000\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1518 - accuracy: 0.3716 - auc: 1.0000\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1515 - accuracy: 0.3658 - auc: 1.0000\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1513 - accuracy: 0.3755 - auc: 1.0000\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1511 - accuracy: 0.3599 - auc: 1.0000\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1509 - accuracy: 0.3677 - auc: 1.0000\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1507 - accuracy: 0.3677 - auc: 1.0000\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1504 - accuracy: 0.3716 - auc: 1.0000\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1502 - accuracy: 0.3677 - auc: 1.0000\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1500 - accuracy: 0.3560 - auc: 1.0000\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1498 - accuracy: 0.3599 - auc: 1.0000\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1495 - accuracy: 0.3599 - auc: 1.0000\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1493 - accuracy: 0.3541 - auc: 1.0000\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1491 - accuracy: 0.3599 - auc: 1.0000\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1489 - accuracy: 0.3580 - auc: 1.0000\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1487 - accuracy: 0.3619 - auc: 1.0000\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1485 - accuracy: 0.3677 - auc: 1.0000\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1482 - accuracy: 0.3599 - auc: 1.0000\n",
            "Test accuracy: 0.8620689655172413, AUC: 0.963768115942029 .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py:436: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  nparray = values.astype(dtype.as_numpy_dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 9s 53ms/step - loss: 36.5502 - accuracy: 0.5778 - auc: 0.6749\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 19.4619 - accuracy: 0.4708 - auc: 0.6947\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 16.5620 - accuracy: 0.4553 - auc: 0.6722\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 8.6384 - accuracy: 0.3794 - auc: 0.7347\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 5.1291 - accuracy: 0.3307 - auc: 0.8233\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 7.6712 - accuracy: 0.3463 - auc: 0.7794\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 1.5071 - accuracy: 0.3482 - auc: 0.9420\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1967 - accuracy: 0.3560 - auc: 0.9999\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1888 - accuracy: 0.3541 - auc: 1.0000\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1908 - accuracy: 0.3424 - auc: 0.9999\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1826 - accuracy: 0.3677 - auc: 1.0000\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1824 - accuracy: 0.3405 - auc: 1.0000\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1816 - accuracy: 0.3463 - auc: 1.0000\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1814 - accuracy: 0.3696 - auc: 1.0000\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1811 - accuracy: 0.3580 - auc: 1.0000\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1810 - accuracy: 0.3521 - auc: 1.0000\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1805 - accuracy: 0.3580 - auc: 1.0000\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1804 - accuracy: 0.3560 - auc: 1.0000\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1804 - accuracy: 0.3638 - auc: 1.0000\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1798 - accuracy: 0.3619 - auc: 1.0000\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1796 - accuracy: 0.3541 - auc: 1.0000\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1794 - accuracy: 0.3658 - auc: 1.0000\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1791 - accuracy: 0.3521 - auc: 1.0000\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1788 - accuracy: 0.3560 - auc: 1.0000\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1786 - accuracy: 0.3619 - auc: 1.0000\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1784 - accuracy: 0.3482 - auc: 1.0000\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1781 - accuracy: 0.3580 - auc: 1.0000\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1778 - accuracy: 0.3638 - auc: 1.0000\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1777 - accuracy: 0.3482 - auc: 1.0000\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1774 - accuracy: 0.3541 - auc: 1.0000\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1771 - accuracy: 0.3580 - auc: 1.0000\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1769 - accuracy: 0.3482 - auc: 1.0000\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1767 - accuracy: 0.3521 - auc: 1.0000\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1764 - accuracy: 0.3599 - auc: 1.0000\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1762 - accuracy: 0.3521 - auc: 1.0000\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1759 - accuracy: 0.3521 - auc: 1.0000\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1757 - accuracy: 0.3560 - auc: 1.0000\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1755 - accuracy: 0.3444 - auc: 1.0000\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1752 - accuracy: 0.3482 - auc: 1.0000\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1750 - accuracy: 0.3463 - auc: 1.0000\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1747 - accuracy: 0.3541 - auc: 1.0000\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1745 - accuracy: 0.3502 - auc: 1.0000\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1743 - accuracy: 0.3541 - auc: 1.0000\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1740 - accuracy: 0.3502 - auc: 1.0000\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1738 - accuracy: 0.3521 - auc: 1.0000\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1735 - accuracy: 0.3502 - auc: 1.0000\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1733 - accuracy: 0.3463 - auc: 1.0000\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1731 - accuracy: 0.3502 - auc: 1.0000\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1728 - accuracy: 0.3502 - auc: 1.0000\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1726 - accuracy: 0.3463 - auc: 1.0000\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f613a3b4d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test accuracy: 0.8620689655172413, AUC: 0.9565217391304348 .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py:436: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  nparray = values.astype(dtype.as_numpy_dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 9s 52ms/step - loss: 30.6278 - accuracy: 0.4436 - auc: 0.6208\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 20.5098 - accuracy: 0.4339 - auc: 0.6506\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 16.1508 - accuracy: 0.3949 - auc: 0.6419\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 9.0716 - accuracy: 0.3521 - auc: 0.8062\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 2.5306 - accuracy: 0.3191 - auc: 0.9130\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 2.4741 - accuracy: 0.2840 - auc: 0.9121\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 6.0772 - accuracy: 0.3599 - auc: 0.7445\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 5.7499 - accuracy: 0.2977 - auc: 0.7508\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 4.1474 - accuracy: 0.3638 - auc: 0.8206\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 2.3375 - accuracy: 0.3210 - auc: 0.9040\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.9640 - accuracy: 0.3580 - auc: 0.9544\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 1.4993 - accuracy: 0.3911 - auc: 0.9408\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1890 - accuracy: 0.3755 - auc: 0.9999\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1644 - accuracy: 0.4241 - auc: 1.0000\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1642 - accuracy: 0.4261 - auc: 1.0000\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1640 - accuracy: 0.4241 - auc: 1.0000\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1637 - accuracy: 0.4280 - auc: 1.0000\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1635 - accuracy: 0.4241 - auc: 1.0000\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1633 - accuracy: 0.4261 - auc: 1.0000\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1630 - accuracy: 0.4241 - auc: 1.0000\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1628 - accuracy: 0.4280 - auc: 1.0000\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1626 - accuracy: 0.4261 - auc: 1.0000\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1624 - accuracy: 0.4261 - auc: 1.0000\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1621 - accuracy: 0.4202 - auc: 1.0000\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1619 - accuracy: 0.4241 - auc: 1.0000\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1617 - accuracy: 0.4202 - auc: 1.0000\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1614 - accuracy: 0.4280 - auc: 1.0000\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1612 - accuracy: 0.4222 - auc: 1.0000\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1610 - accuracy: 0.4222 - auc: 1.0000\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1608 - accuracy: 0.4280 - auc: 1.0000\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1605 - accuracy: 0.4222 - auc: 1.0000\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1603 - accuracy: 0.4163 - auc: 1.0000\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1601 - accuracy: 0.4241 - auc: 1.0000\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1598 - accuracy: 0.4261 - auc: 1.0000\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1596 - accuracy: 0.4125 - auc: 1.0000\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1594 - accuracy: 0.4183 - auc: 1.0000\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1592 - accuracy: 0.4183 - auc: 1.0000\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1589 - accuracy: 0.4163 - auc: 1.0000\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1587 - accuracy: 0.4241 - auc: 1.0000\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1585 - accuracy: 0.4125 - auc: 1.0000\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1582 - accuracy: 0.4222 - auc: 1.0000\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1580 - accuracy: 0.4125 - auc: 1.0000\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1578 - accuracy: 0.4125 - auc: 1.0000\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1576 - accuracy: 0.4222 - auc: 1.0000\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1574 - accuracy: 0.4144 - auc: 1.0000\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1571 - accuracy: 0.4183 - auc: 1.0000\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1569 - accuracy: 0.4144 - auc: 1.0000\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1567 - accuracy: 0.4125 - auc: 1.0000\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1565 - accuracy: 0.4086 - auc: 1.0000\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1562 - accuracy: 0.4144 - auc: 1.0000\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f615d2a3d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test accuracy: 0.8620689655172413, AUC: 0.6499999999999999 .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py:436: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  nparray = values.astype(dtype.as_numpy_dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 9s 55ms/step - loss: 34.0701 - accuracy: 0.4671 - auc: 0.6566\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 24.1194 - accuracy: 0.4186 - auc: 0.6746\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 18.6523 - accuracy: 0.4012 - auc: 0.6431\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 10.4962 - accuracy: 0.4419 - auc: 0.7274\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 9.0838 - accuracy: 0.3953 - auc: 0.7278\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 6.9955 - accuracy: 0.3643 - auc: 0.7241\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.3276 - accuracy: 0.3333 - auc: 0.9890\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.3097 - accuracy: 0.3915 - auc: 0.9919\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 4.2675 - accuracy: 0.3740 - auc: 0.8954\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1636 - accuracy: 0.4089 - auc: 1.0000\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1633 - accuracy: 0.4128 - auc: 1.0000\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1631 - accuracy: 0.4089 - auc: 1.0000\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1629 - accuracy: 0.4109 - auc: 1.0000\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1627 - accuracy: 0.4031 - auc: 1.0000\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1624 - accuracy: 0.4128 - auc: 1.0000\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1622 - accuracy: 0.4070 - auc: 1.0000\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1620 - accuracy: 0.4031 - auc: 1.0000\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1617 - accuracy: 0.4070 - auc: 1.0000\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1615 - accuracy: 0.4050 - auc: 1.0000\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1613 - accuracy: 0.3992 - auc: 1.0000\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1611 - accuracy: 0.4012 - auc: 1.0000\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1608 - accuracy: 0.4089 - auc: 1.0000\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1606 - accuracy: 0.4070 - auc: 1.0000\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1604 - accuracy: 0.4070 - auc: 1.0000\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1601 - accuracy: 0.3992 - auc: 1.0000\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1599 - accuracy: 0.4050 - auc: 1.0000\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1597 - accuracy: 0.4012 - auc: 1.0000\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1595 - accuracy: 0.4070 - auc: 1.0000\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1592 - accuracy: 0.4050 - auc: 1.0000\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1590 - accuracy: 0.4031 - auc: 1.0000\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1588 - accuracy: 0.4050 - auc: 1.0000\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1586 - accuracy: 0.4012 - auc: 1.0000\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1583 - accuracy: 0.3973 - auc: 1.0000\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1581 - accuracy: 0.4012 - auc: 1.0000\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1579 - accuracy: 0.4012 - auc: 1.0000\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1577 - accuracy: 0.4031 - auc: 1.0000\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1574 - accuracy: 0.3992 - auc: 1.0000\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1572 - accuracy: 0.4012 - auc: 1.0000\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1570 - accuracy: 0.4012 - auc: 1.0000\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1568 - accuracy: 0.4031 - auc: 1.0000\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1566 - accuracy: 0.3953 - auc: 1.0000\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1563 - accuracy: 0.3992 - auc: 1.0000\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1561 - accuracy: 0.3953 - auc: 1.0000\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1559 - accuracy: 0.4012 - auc: 1.0000\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1557 - accuracy: 0.3973 - auc: 1.0000\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1554 - accuracy: 0.4012 - auc: 1.0000\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1552 - accuracy: 0.3934 - auc: 1.0000\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1550 - accuracy: 0.3915 - auc: 1.0000\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1548 - accuracy: 0.3953 - auc: 1.0000\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1546 - accuracy: 0.3953 - auc: 1.0000\n",
            "Test accuracy: 0.8214285714285714, AUC: 0.9545454545454546 .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py:436: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  nparray = values.astype(dtype.as_numpy_dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 7 ...\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 9s 52ms/step - loss: 35.0436 - accuracy: 0.4729 - auc: 0.6250\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 29.4999 - accuracy: 0.4554 - auc: 0.6473\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 12.9205 - accuracy: 0.4864 - auc: 0.7134\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 10.0911 - accuracy: 0.3740 - auc: 0.7388\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 15.1942 - accuracy: 0.4147 - auc: 0.6068\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 6.9466 - accuracy: 0.3547 - auc: 0.8021\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 3.7555 - accuracy: 0.4109 - auc: 0.8881\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 1.5009 - accuracy: 0.3547 - auc: 0.9397\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 3.5762 - accuracy: 0.3585 - auc: 0.8640\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 2.5005 - accuracy: 0.3566 - auc: 0.9170\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.2138 - accuracy: 0.4147 - auc: 0.9994\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 2.1379 - accuracy: 0.3740 - auc: 0.9329\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1670 - accuracy: 0.4322 - auc: 1.0000\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1667 - accuracy: 0.4399 - auc: 1.0000\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1669 - accuracy: 0.4322 - auc: 1.0000\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1663 - accuracy: 0.4457 - auc: 1.0000\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1665 - accuracy: 0.4147 - auc: 1.0000\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1661 - accuracy: 0.4167 - auc: 1.0000\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1659 - accuracy: 0.4399 - auc: 1.0000\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1653 - accuracy: 0.4419 - auc: 1.0000\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1652 - accuracy: 0.4225 - auc: 1.0000\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1649 - accuracy: 0.4380 - auc: 1.0000\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1646 - accuracy: 0.4419 - auc: 1.0000\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1644 - accuracy: 0.4360 - auc: 1.0000\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1641 - accuracy: 0.4380 - auc: 1.0000\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1640 - accuracy: 0.4283 - auc: 1.0000\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1637 - accuracy: 0.4360 - auc: 1.0000\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1634 - accuracy: 0.4341 - auc: 1.0000\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1632 - accuracy: 0.4360 - auc: 1.0000\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1629 - accuracy: 0.4341 - auc: 1.0000\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1627 - accuracy: 0.4341 - auc: 1.0000\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1625 - accuracy: 0.4419 - auc: 1.0000\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1622 - accuracy: 0.4438 - auc: 1.0000\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1620 - accuracy: 0.4419 - auc: 1.0000\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1618 - accuracy: 0.4283 - auc: 1.0000\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1616 - accuracy: 0.4419 - auc: 1.0000\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1613 - accuracy: 0.4380 - auc: 1.0000\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1611 - accuracy: 0.4419 - auc: 1.0000\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1609 - accuracy: 0.4341 - auc: 1.0000\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1606 - accuracy: 0.4438 - auc: 1.0000\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1604 - accuracy: 0.4380 - auc: 1.0000\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1602 - accuracy: 0.4360 - auc: 1.0000\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1600 - accuracy: 0.4380 - auc: 1.0000\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1597 - accuracy: 0.4419 - auc: 1.0000\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1595 - accuracy: 0.4399 - auc: 1.0000\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1593 - accuracy: 0.4380 - auc: 1.0000\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1591 - accuracy: 0.4360 - auc: 1.0000\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1590 - accuracy: 0.4283 - auc: 1.0000\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1586 - accuracy: 0.4244 - auc: 1.0000\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1584 - accuracy: 0.4419 - auc: 1.0000\n",
            "Test accuracy: 0.8571428571428571, AUC: 0.8877551020408163 .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py:436: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  nparray = values.astype(dtype.as_numpy_dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 8 ...\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 9s 53ms/step - loss: 39.6410 - accuracy: 0.4283 - auc: 0.5936\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 28.1360 - accuracy: 0.4864 - auc: 0.6390\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 17.9143 - accuracy: 0.4477 - auc: 0.6715\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 13.3691 - accuracy: 0.4806 - auc: 0.7781\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 10.2554 - accuracy: 0.4554 - auc: 0.7480\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 4.6833 - accuracy: 0.4612 - auc: 0.8515\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 9.0839 - accuracy: 0.4690 - auc: 0.7674\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 6.4026 - accuracy: 0.4457 - auc: 0.8351\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 3.0400 - accuracy: 0.4632 - auc: 0.9007\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 4.8538 - accuracy: 0.4845 - auc: 0.8103\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 1.6740 - accuracy: 0.4729 - auc: 0.9384\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1732 - accuracy: 0.4690 - auc: 1.0000\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.2019 - accuracy: 0.4729 - auc: 0.9961\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 7.2164 - accuracy: 0.4167 - auc: 0.7972\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1725 - accuracy: 0.4787 - auc: 1.0000\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1723 - accuracy: 0.4787 - auc: 1.0000\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1720 - accuracy: 0.4767 - auc: 1.0000\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1718 - accuracy: 0.4787 - auc: 1.0000\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1716 - accuracy: 0.4767 - auc: 1.0000\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1713 - accuracy: 0.4787 - auc: 1.0000\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1711 - accuracy: 0.4767 - auc: 1.0000\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1708 - accuracy: 0.4767 - auc: 1.0000\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1706 - accuracy: 0.4767 - auc: 1.0000\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1704 - accuracy: 0.4787 - auc: 1.0000\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1701 - accuracy: 0.4767 - auc: 1.0000\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1699 - accuracy: 0.4787 - auc: 1.0000\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1697 - accuracy: 0.4767 - auc: 1.0000\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1694 - accuracy: 0.4767 - auc: 1.0000\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1692 - accuracy: 0.4767 - auc: 1.0000\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1690 - accuracy: 0.4767 - auc: 1.0000\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1687 - accuracy: 0.4767 - auc: 1.0000\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1685 - accuracy: 0.4787 - auc: 1.0000\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1683 - accuracy: 0.4787 - auc: 1.0000\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1680 - accuracy: 0.4787 - auc: 1.0000\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1678 - accuracy: 0.4767 - auc: 1.0000\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1676 - accuracy: 0.4748 - auc: 1.0000\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1673 - accuracy: 0.4787 - auc: 1.0000\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1671 - accuracy: 0.4787 - auc: 1.0000\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1669 - accuracy: 0.4787 - auc: 1.0000\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1667 - accuracy: 0.4767 - auc: 1.0000\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1664 - accuracy: 0.4767 - auc: 1.0000\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1662 - accuracy: 0.4787 - auc: 1.0000\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1660 - accuracy: 0.4748 - auc: 1.0000\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1657 - accuracy: 0.4787 - auc: 1.0000\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1655 - accuracy: 0.4729 - auc: 1.0000\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1653 - accuracy: 0.4748 - auc: 1.0000\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1650 - accuracy: 0.4767 - auc: 1.0000\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1648 - accuracy: 0.4748 - auc: 1.0000\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1646 - accuracy: 0.4767 - auc: 1.0000\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1643 - accuracy: 0.4748 - auc: 1.0000\n",
            "Test accuracy: 0.9285714285714286, AUC: 0.859375 .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py:436: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  nparray = values.astype(dtype.as_numpy_dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 9 ...\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 9s 52ms/step - loss: 34.7225 - accuracy: 0.4729 - auc: 0.6248\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 26.4791 - accuracy: 0.4419 - auc: 0.6598\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 17.2579 - accuracy: 0.4554 - auc: 0.7111\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 19.8289 - accuracy: 0.4787 - auc: 0.6195\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 11.1062 - accuracy: 0.4612 - auc: 0.7393\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 3.9575 - accuracy: 0.4050 - auc: 0.8808\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 6.4934 - accuracy: 0.4399 - auc: 0.8117\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 6.4906 - accuracy: 0.4360 - auc: 0.7848\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 2.6213 - accuracy: 0.3837 - auc: 0.9162\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1730 - accuracy: 0.4574 - auc: 1.0000\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1727 - accuracy: 0.4574 - auc: 1.0000\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1725 - accuracy: 0.4554 - auc: 1.0000\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1723 - accuracy: 0.4535 - auc: 1.0000\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1720 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1718 - accuracy: 0.4574 - auc: 1.0000\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1716 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1713 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1711 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1709 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1706 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1704 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1702 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1699 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1697 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1695 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1693 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1690 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1688 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1686 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1683 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1681 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1679 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1676 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1674 - accuracy: 0.4496 - auc: 1.0000\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1672 - accuracy: 0.4574 - auc: 1.0000\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.1669 - accuracy: 0.4535 - auc: 1.0000\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1667 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.1665 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.1663 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.1660 - accuracy: 0.4496 - auc: 1.0000\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1658 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1656 - accuracy: 0.4496 - auc: 1.0000\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1653 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1651 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.1649 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.1647 - accuracy: 0.4496 - auc: 1.0000\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1644 - accuracy: 0.4516 - auc: 1.0000\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1642 - accuracy: 0.4496 - auc: 1.0000\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1640 - accuracy: 0.4496 - auc: 1.0000\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.1638 - accuracy: 0.4496 - auc: 1.0000\n",
            "Test accuracy: 0.8214285714285714, AUC: 0.9848484848484849 .\n",
            "Average 10-fold CV accuracy: 0.8566502463054186, AUC: 0.907694376663709 .\n",
            "SD of 10-fold CV accuracy: 0.033201933899498985, AUC: 0.09319974573305305 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_probs.argmax(1)"
      ],
      "metadata": {
        "id": "Rq9UFT51-LMV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6443cd6a-b35a-43bf-c6e1-36e3e5b0480e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cv_accs)"
      ],
      "metadata": {
        "id": "36Ovx9cE99mz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7d96dfe-c3ef-42e9-81fa-1257b170b509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.896551724137931, 0.8275862068965517, 0.8275862068965517, 0.8620689655172413, 0.8620689655172413, 0.8620689655172413, 0.8214285714285714, 0.8571428571428571, 0.9285714285714286, 0.8214285714285714]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cv_aucs)"
      ],
      "metadata": {
        "id": "N6R6YyHiBAAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "991e410a-dbc8-49b1-ccd0-e4960f213442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9545454545454546, 0.9155844155844155, 0.95, 0.963768115942029, 0.9565217391304348, 0.6499999999999999, 0.9545454545454546, 0.8877551020408163, 0.859375, 0.9848484848484849]\n"
          ]
        }
      ]
    }
  ]
}